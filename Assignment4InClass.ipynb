{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beanb36/Acoustic-Modelling-project/blob/main/Assignment4InClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIibLvnlp1yW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold,GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZMdnqH3zrsF",
        "outputId": "b5ba5e31-638e-407a-e155-7fa85716be39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "HouseDF=pd.read_csv('gdrive/My Drive/housing.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V4pZ3xzz66V"
      },
      "outputs": [],
      "source": [
        "# Extract features and target\n",
        "X = HouseDF[['housing_median_age', 'total_rooms',\n",
        "'total_bedrooms', 'population', 'households', 'median_income','ocean_proximity']]\n",
        "X = pd.get_dummies(X, columns=['ocean_proximity'], drop_first=True)\n",
        "y = HouseDF['median_house_value']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCsmyPMXz_yT"
      },
      "outputs": [],
      "source": [
        "# Handle missing values by filling NaNs with the mean of the column\n",
        "X = X.fillna(X.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGJSIjcg0DD_"
      },
      "outputs": [],
      "source": [
        "# Standardize the features after filling missing values\n",
        "std_scaler = StandardScaler()\n",
        "X = std_scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNf8qUKR0IW7"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "percentile_25 = y_train.quantile(0.25)\n",
        "percentile_75 = y_train.quantile(0.75)\n",
        "\n",
        "y_train_cat = pd.cut(y_train, bins=[0, percentile_25, percentile_75, float('inf')],\n",
        "                      labels=['poor', 'med', 'rich'])\n",
        "y_test_cat = pd.cut(y_test, bins=[0, percentile_25, percentile_75, float('inf')],\n",
        "                     labels=['poor', 'med', 'rich'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YzvwkiHA9qp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a classification model (example using DecisionTreeClassifier)\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train_cat)\n",
        "\n",
        "# Get predictions from the classification model\n",
        "dt_pred_cat = dt_classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "Eg_FyEFB_-Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Train the best Random Forest model\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train_cat)\n",
        "\n",
        "rf_pred_cat = rf_classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "GLilt7ZRABAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.classifier import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "  ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
        "  ('gb', GradientBoostingClassifier(n_estimators=50, random_state=42)),\n",
        "  ('svc', SVC(probability=True, random_state=42))\n",
        "]\n",
        "# Define meta-learner\n",
        "meta_model = LogisticRegression()\n",
        "# Build Stacking Classifier\n",
        "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "stacking_clf.fit(X_train, y_train_cat)  # Changed to y_train_cat for classification\n",
        "\n",
        "# Predictions\n",
        "stacking_pred_cat = stacking_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "glhCvyYXB_oN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "6aff7c99-80ae-4ccb-d330-f9428d91d550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "StackingClassifier.__init__() got an unexpected keyword argument 'estimators'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b40f0e52408b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmeta_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Build Stacking Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mstacking_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: StackingClassifier.__init__() got an unexpected keyword argument 'estimators'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuer Abschnitt"
      ],
      "metadata": {
        "id": "1fKI2yHeSSnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test_cat, stacking_pred_cat, labels=['poor', 'med', 'rich'])\n",
        "\n",
        "# Display confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['poor', 'med', 'rich'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title('Confusion Matrix for Stacking Classifier')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eQgrNX68CW1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test_cat, dt_pred_cat, labels=['poor', 'med', 'rich'])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['poor', 'med', 'rich'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title('Confusion Matrix for Decision Tree Classifier')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GNdsY4yF9vWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test_cat, rf_pred_cat, labels=['poor', 'med', 'rich'])\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['poor', 'med', 'rich'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title('Confusion Matrix for Random Forest')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qcKqdtfeAdcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Decision Tree\n",
        "dt_accuracy = accuracy_score(y_test_cat, dt_pred_cat)\n",
        "dt_precision = precision_score(y_test_cat, dt_pred_cat, average='weighted')\n",
        "dt_recall = recall_score(y_test_cat, dt_pred_cat, average='weighted')\n",
        "dt_f1 = f1_score(y_test_cat, dt_pred_cat, average='weighted')\n",
        "\n",
        "# Random Forest\n",
        "rf_accuracy = accuracy_score(y_test_cat, rf_pred_cat)\n",
        "rf_precision = precision_score(y_test_cat, rf_pred_cat, average='weighted')\n",
        "rf_recall = recall_score(y_test_cat, rf_pred_cat, average='weighted')\n",
        "rf_f1 = f1_score(y_test_cat, rf_pred_cat, average='weighted')\n",
        "\n",
        "# Stacking Classifier\n",
        "stacking_accuracy = accuracy_score(y_test_cat, stacking_pred_cat)\n",
        "stacking_precision = precision_score(y_test_cat, stacking_pred_cat, average='weighted')\n",
        "stacking_recall = recall_score(y_test_cat, stacking_pred_cat, average='weighted')\n",
        "stacking_f1 = f1_score(y_test_cat, stacking_pred_cat, average='weighted')\n",
        "\n",
        "print(\"Decision Tree:\")\n",
        "print(f\"  Accuracy: {dt_accuracy:.4f}\")\n",
        "print(f\"  Precision: {dt_precision:.4f}\")\n",
        "print(f\"  Recall: {dt_recall:.4f}\")\n",
        "print(f\"  F1-score: {dt_f1:.4f}\")\n",
        "\n",
        "print(\"\\nRandom Forest:\")\n",
        "print(f\"  Accuracy: {rf_accuracy:.4f}\")\n",
        "print(f\"  Precision: {rf_precision:.4f}\")\n",
        "print(f\"  Recall: {rf_recall:.4f}\")\n",
        "print(f\"  F1-score: {rf_f1:.4f}\")\n",
        "\n",
        "print(\"\\nStacking Classifier:\")\n",
        "print(f\"  Accuracy: {stacking_accuracy:.4f}\")\n",
        "print(f\"  Precision: {stacking_precision:.4f}\")\n",
        "print(f\"  Recall: {stacking_recall:.4f}\")\n",
        "print(f\"  F1-score: {stacking_f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "wARSjmTBIT8s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP9Rdp9sBIcS6ZqY+7R5/w8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}